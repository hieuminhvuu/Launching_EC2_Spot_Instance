[
{
	"uri": "https://hieuminhvuu.github.io/Launching_EC2_Spot_Instance/",
	"title": "Launching EC2 Spot Instances",
	"tags": [],
	"description": "",
	"content": "Launching EC2 Spot Instances Overview In this workshop you learn about the fundamentals of EC2 Spot Instances and recommended tools to launch Spot Instances, test for resiliency, and view pricing history.\nYou play the role of a DevOps engineer who is given a sample application and tasked to deploy it cost efficiently using EC2 Auto Scaling groups and EC2 Fleet in an optimal AWS Region. Post deployment you simulate Spot Instance interruptions to test the resiliency of Auto Scaling groups, and finally calculate the estimated cost savings.\nEstimated time and cost to run this workshop The estimated time for completing the workshop is 45 to 60 minutes. The estimated cost is less than $5.\nContent Starting the workshop Creating a launch template Launching EC2 spot instances via EC2 auto scaling group Launching EC2 spot instances via EC2 fleet Creating a spot interruption experiment Saving summary Spot placement score Spot Blueprint Clean up "
},
{
	"uri": "https://hieuminhvuu.github.io/Launching_EC2_Spot_Instance/1-starting_the_workshop/",
	"title": "Starting the workshop",
	"tags": [],
	"description": "",
	"content": "To provision AWS resources in a programmatic manner you run AWS Command Line Interface (CLI) commands in AWS CloudShell. All the CLI commands you are going to run can be reproduced using CloudFormation, AWS SDKs, and Terraform.\nAWS CloudShell AWS CloudShell is a browser-based shell console that makes it easy to securely manage, explore, and interact with your AWS resources. To launch CloudShell click on the shortcut available in the top navigation bar (highlighted in green in below image), or simply click on this AWS CloudShell console link.\nYou can use the example below to find out which is the region you are currently connected to (region is highlighted in red). All the resources that you create throughout the workshop are deployed in the selected region.\n"
},
{
	"uri": "https://hieuminhvuu.github.io/Launching_EC2_Spot_Instance/2-creating_a_launch_template/",
	"title": "Creating a launch template",
	"tags": [],
	"description": "",
	"content": "As a prerequisite step before creating EC2 Auto Scaling groups or EC2 Fleet, you create a launch template. Launch templates enable you to define launch parameters so that you do not have to specify them every time you launch an instance. It includes the ID of the Amazon Machine Image (AMI), the instance type, a key pair, security groups, and other parameters used to launch EC2 instances.\nDuring this workshop, you use your account’s default VPC to create the instances.\nCreating a launch template Create launch-template-data.json configuration file in CloudShell by running below commands. When you examine the configuration, you notice that ImageId parameter has a placeholder value %ami-id%, and UserData contains a base64 encoded Webserver installation steps. Once you have created the launch template, you can describe it and decode the user-data to view the content. cat \u0026lt;\u0026lt; EOF \u0026gt; launch-template-data.json { \u0026#34;ImageId\u0026#34;: \u0026#34;%ami-id%\u0026#34;, \u0026#34;TagSpecifications\u0026#34;: [ { \u0026#34;ResourceType\u0026#34;: \u0026#34;instance\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Name\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;mySpotWorkshop\u0026#34; } ] } ], \u0026#34;UserData\u0026#34;: \u0026#34;I2Nsb3VkLWNvbmZpZwpyZXBvX3VwZGF0ZTogdHJ1ZQpyZXBvX3VwZ3JhZGU6IGFsbAoKcGFja2FnZXM6CiAgLSBodHRwZAogIC0gY3VybAoKcnVuY21kOgogIC0gWyBzaCwgLWMsICJhbWF6b24tbGludXgtZXh0cmFzIGluc3RhbGwgLXkgZXBlbCIgXQogIC0gWyBzaCwgLWMsICJ5dW0gLXkgaW5zdGFsbCBzdHJlc3MtbmciIF0KICAtIFsgc2gsIC1jLCAiZWNobyBoZWxsbyB3b3JsZC4gTXkgaW5zdGFuY2UtaWQgaXMgJChjdXJsIC1zIGh0dHA6Ly8xNjkuMjU0LjE2OS4yNTQvbGF0ZXN0L21ldGEtZGF0YS9pbnN0YW5jZS1pZCkuIE15IGluc3RhbmNlLXR5cGUgaXMgJChjdXJsIC1zIGh0dHA6Ly8xNjkuMjU0LjE2OS4yNTQvbGF0ZXN0L21ldGEtZGF0YS9pbnN0YW5jZS10eXBlKS4gPiAvdmFyL3d3dy9odG1sL2luZGV4Lmh0bWwiIF0KICAtIFsgc2gsIC1jLCAic3lzdGVtY3RsIGVuYWJsZSBodHRwZCIgXQogIC0gWyBzaCwgLWMsICJzeXN0ZW1jdGwgc3RhcnQgaHR0cGQiIF0KCgo=\u0026#34; } EOF The variable %ami-id% should be replaced with the latest Amazon Linux 2 AMI. You pull the latest Amazon Linux 2 AMI ID and update the AMI Id in your configuration file by running following commands. # First, this command looks up the latest Amazon Linux 2 AMI export ami_id=$(aws ec2 describe-images --owners amazon --filters \u0026#34;Name=name,Values=amzn2-ami-kernel*gp2\u0026#34; \u0026#34;Name=virtualization-type,Values=hvm\u0026#34; \u0026#34;Name=root-device-type,Values=ebs\u0026#34; --query \u0026#34;sort_by(Images, \u0026amp;CreationDate)[-1].ImageId\u0026#34; --output text) sed -i.bak -e \u0026#34;s#%instanceProfile%#$instanceProfile#g\u0026#34; -e \u0026#34;s#%ami-id%#$ami_id#g\u0026#34; launch-template-data.json Create the launch template using the config you just updated. You can check other parameters supported by launch template here. aws ec2 create-launch-template --launch-template-name TemplateForWebServer --launch-template-data file://launch-template-data.json Example return\n{ \u0026#34;LaunchTemplate\u0026#34;: { \u0026#34;CreateTime\u0026#34;: \u0026#34;2019-02-14T05:53:07.000Z\u0026#34;, \u0026#34;LaunchTemplateName\u0026#34;: \u0026#34;TemplateForWebServer\u0026#34;, \u0026#34;DefaultVersionNumber\u0026#34;: 1, \u0026#34;CreatedBy\u0026#34;: \u0026#34;arn:aws:iam::123456789012:user/xxxxxxxx\u0026#34;, \u0026#34;LatestVersionNumber\u0026#34;: 1, \u0026#34;LaunchTemplateId\u0026#34;: \u0026#34;lt-00ac79500cbd56d11\u0026#34; } } Take a look at the user-data script configured on the launch template to understand what is installed on the instances while being bootstrapped. aws ec2 describe-launch-template-versions --launch-template-name TemplateForWebServer --output json | jq -r \u0026#39;.LaunchTemplateVersions[].LaunchTemplateData.UserData\u0026#39; | base64 --decode Example return\n#cloud-config repo_update: true repo_upgrade: all packages: - httpd - curl runcmd: - [ sh, -c, \u0026#34;amazon-linux-extras install -y epel\u0026#34; ] - [ sh, -c, \u0026#34;yum -y install stress-ng\u0026#34; ] - [ sh, -c, \u0026#34;echo hello world. My instance-id is $(curl -s http://169.254.169.254/latest/meta-data/instance-id). My instance-type is $(curl -s http://169.254.169.254/latest/meta-data/instance-type). \u0026gt; /var/www/html/index.html\u0026#34; ] - [ sh, -c, \u0026#34;systemctl enable httpd\u0026#34; ] - [ sh, -c, \u0026#34;systemctl start httpd\u0026#34; ] As the last step of this section, you are going to perform an additional API call to retrieve the identifier of the launch template that was just created and store it in an environment variable. You use this launch template ID when creating Auto Scaling groups, EC2 Fleets, and Spot Fleets. export LAUNCH_TEMPLATE_ID=$(aws ec2 describe-launch-templates --filters Name=launch-template-name,Values=TemplateForWebServer | jq -r \u0026#39;.LaunchTemplates[0].LaunchTemplateId\u0026#39;) Well done! You have created a launch template and stored into environment variables all the details that you need to refer to it in the next steps.\n"
},
{
	"uri": "https://hieuminhvuu.github.io/Launching_EC2_Spot_Instance/3-launching_ec2_spot_instances_via_ec2_auto_scaling_group/",
	"title": "Launching EC2 spot instances via EC2 auto scaling group",
	"tags": [],
	"description": "",
	"content": "\rWhen adopting EC2 Spot Instances, we recommend you to consider Amazon EC2 Auto Scaling group (ASG) since it offers the most up to date EC2 features such as attribute-based instance type selection, capacity rebalancing, scaling policies and many more functionalities.\nAmazon EC2 Auto Scaling groups contain a collection of Amazon EC2 Instances that are treated as a logical grouping for the purposes of automatic scaling and management. Auto Scaling groups also enable you to use Amazon EC2 Auto Scaling features such as health check replacements and scaling policies. Both maintaining the number of instances in an Auto Scaling group and automatic scaling are the core functionality of the Amazon EC2 Auto Scaling service.\nIn the past, Auto Scaling groups used launch configurations. Applications using launch configurations should migrate to launch templates so that you can leverage the latest features. With launch templates you can provision capacity across multiple instance types using both Spot Instances and On-Demand Instances to achieve the desired scale, performance, and cost optimization.\nUsing attribute-based instance type selection and mixed instance groups Being instance flexible is an important Spot best practice, you can use attribute-based instance type selection (ABIS) to automatically select multiple instance types matching your requirements. A common case when using Auto Scaling groups, is to use it with workloads that require a mix of Spot and On-Demand capacity.\nIn this step you create a json file for creating Auto Scaling groups using AWS CLI. The configuration uses the launch template that you created in the previous steps and ABIS to pick any current generation non-GPU instance types with 2 vCPU and no limit on memory. OnDemandBaseCapacity allows you to set an initial capacity of 1 On-Demand Instance. Remaining capacity is mix of 25% On-Demand Instances and 75% Spot Instances defined by the OnDemandPercentageAboveBaseCapacity.\ncat \u0026lt;\u0026lt;EoF \u0026gt; ./asg-policy.json { \u0026#34;LaunchTemplate\u0026#34;:{ \u0026#34;LaunchTemplateSpecification\u0026#34;:{ \u0026#34;LaunchTemplateId\u0026#34;:\u0026#34;${LAUNCH_TEMPLATE_ID}\u0026#34;, \u0026#34;Version\u0026#34;:\u0026#34;1\u0026#34; }, \u0026#34;Overrides\u0026#34;:[{ \u0026#34;InstanceRequirements\u0026#34;: { \u0026#34;VCpuCount\u0026#34;: { \u0026#34;Min\u0026#34;: 2, \u0026#34;Max\u0026#34;: 2 }, \u0026#34;MemoryMiB\u0026#34;: { \u0026#34;Min\u0026#34;: 0 }, \u0026#34;CpuManufacturers\u0026#34;: [ \u0026#34;intel\u0026#34;, \u0026#34;amd\u0026#34; ], \u0026#34;InstanceGenerations\u0026#34;: [ \u0026#34;current\u0026#34; ], \u0026#34;AcceleratorCount\u0026#34;: { \u0026#34;Max\u0026#34;: 0 } } }] }, \u0026#34;InstancesDistribution\u0026#34;:{ \u0026#34;OnDemandBaseCapacity\u0026#34;:1, \u0026#34;OnDemandPercentageAboveBaseCapacity\u0026#34;:25, \u0026#34;SpotAllocationStrategy\u0026#34;:\u0026#34;price-capacity-optimized\u0026#34; } } EoF In this configuration you set the SpotAllocationStrategy to price-capacity-optimized. The price-capacity-optimized allocation strategy allocates instances from the Spot Instance pools that offer low prices and high capacity availability. You can read more about the price-capacity-optimized allocation strategy in Introducing the price-capacity-optimized allocation strategy for EC2 Spot Instances blog post.\nRun the following commands to retrieve your default VPC and then its subnets. export VPC_ID=$(aws ec2 describe-vpcs --filters Name=isDefault,Values=true | jq -r \u0026#39;.Vpcs[0].VpcId\u0026#39;) export SUBNETS=$(aws ec2 describe-subnets --filters Name=vpc-id,Values=\u0026#34;${VPC_ID}\u0026#34;) export SUBNET_1=$((echo $SUBNETS) | jq -r \u0026#39;.Subnets[0].SubnetId\u0026#39;) export SUBNET_2=$((echo $SUBNETS) | jq -r \u0026#39;.Subnets[1].SubnetId\u0026#39;) Run the following commands to create an Auto Scaling group across 2 Availability Zones, min-size 2, max-size 20, and desired-capacity 10 vCPU units. aws autoscaling create-auto-scaling-group --auto-scaling-group-name EC2SpotWorkshopASG --min-size 2 --max-size 20 --desired-capacity 10 --desired-capacity-type vcpu --vpc-zone-identifier \u0026#34;${SUBNET_1},${SUBNET_2}\u0026#34; --capacity-rebalance --mixed-instances-policy file://asg-policy.json You have now created a mixed instances Auto Scaling group!\n"
},
{
	"uri": "https://hieuminhvuu.github.io/Launching_EC2_Spot_Instance/4-launching_ec2_spot_instance_via_ec2_fleet/",
	"title": "Launching EC2 spot instances via EC2 fleet",
	"tags": [],
	"description": "",
	"content": "EC2 Fleet provides an API that allows to operate and procure capacity with quite granular controls. An EC2 Fleet contains the configuration information to launch a fleet or group of instances. Using EC2 Fleet, you can define separate On-Demand and Spot capacity targets, specify the instance types that work best for your applications, and specify how Amazon EC2 should distribute your fleet capacity within each purchasing model.\nWorkloads that can benefit from EC2 Fleet API are among other bespoke capacity orchestrators that implement tuned up and optimized logic to provision capacity. Just to name a few, the following projects use EC2 Fleet to manage capacity:\nKarpenter. Karpenter is Kubernetes Cluster Autoscaler. It manages the node lifecycle. It observes incoming pods and launches the right instances for the situation. Atlassian Escalator, yet another Kubernetes Cluster Autoscaler. Designed for large batch or job based workloads that cannot be force-drained and moved when the cluster needs to scale down. EC2 Fleet example : Applying instance diversification on HPC tightly coupled workloads with EC2 Fleet instant mode In this part of the workshop you tackle a common workload for with EC2 Fleet provides benefit when running.\nNote that while using Spot Instances, most of MPI workloads, specially those that run for hours and do not use checkpointing, are not appropriate for Spot Instances. Remember Spot Instances are suited for fault tolerant applications that can recover from the loss and replacement of one or more instances.\nIn this part of the workshop you request an EC2 Fleet using the request type instant, which is a feature only available in EC2 Fleet. By doing so, EC2 Fleet places a synchronous one-time request for your desired capacity. In the API response, it returns the instances that launched, along with errors for those instances that could not be launched. More information on request types here.\nTightly coupled HPC workloads typically suffer from performance degradation when the instances in the cluster are of different instance families and sizes (i.e: c5.large vs c4.large or c5.large vs c5.xlarge). The other characteristic of this workload is that all the instances must be close together (ideally in the same placement group). To satisfy these constraints you configure the fleet request with same instance type (for example c5.large) in a single Availability Zone. If your HPC application is loosely coupled and you can remove these constraints and use Auto Scaling groups instead.\nCreate the configuration file to launch the EC2 Fleet with attribute-based instance type selection (ABIS). Run the following: cat \u0026lt;\u0026lt;EoF \u0026gt; ./ec2-fleet-config.json { \u0026#34;SpotOptions\u0026#34;:{ \u0026#34;SingleInstanceType\u0026#34;: true, \u0026#34;SingleAvailabilityZone\u0026#34;: true, \u0026#34;MinTargetCapacity\u0026#34;: 4, \u0026#34;AllocationStrategy\u0026#34;: \u0026#34;price-capacity-optimized\u0026#34;, \u0026#34;InstanceInterruptionBehavior\u0026#34;: \u0026#34;terminate\u0026#34; }, \u0026#34;OnDemandOptions\u0026#34;:{ \u0026#34;AllocationStrategy\u0026#34;: \u0026#34;lowest-price\u0026#34;, \u0026#34;SingleInstanceType\u0026#34;: true, \u0026#34;SingleAvailabilityZone\u0026#34;: true, \u0026#34;MinTargetCapacity\u0026#34;: 0 }, \u0026#34;LaunchTemplateConfigs\u0026#34;:[ { \u0026#34;LaunchTemplateSpecification\u0026#34;:{ \u0026#34;LaunchTemplateId\u0026#34;:\u0026#34;${LAUNCH_TEMPLATE_ID}\u0026#34;, \u0026#34;Version\u0026#34;:\u0026#34;1\u0026#34; }, \u0026#34;Overrides\u0026#34;:[{ \u0026#34;InstanceRequirements\u0026#34;: { \u0026#34;VCpuCount\u0026#34;: { \u0026#34;Min\u0026#34;: 2, \u0026#34;Max\u0026#34;: 4 }, \u0026#34;MemoryMiB\u0026#34;: { \u0026#34;Min\u0026#34;: 0 }, \u0026#34;CpuManufacturers\u0026#34;: [ \u0026#34;intel\u0026#34; ] } }] } ], \u0026#34;TargetCapacitySpecification\u0026#34;:{ \u0026#34;TotalTargetCapacity\u0026#34;: 4, \u0026#34;OnDemandTargetCapacity\u0026#34;: 0, \u0026#34;DefaultTargetCapacityType\u0026#34;: \u0026#34;spot\u0026#34; }, \u0026#34;Type\u0026#34;:\u0026#34;instant\u0026#34; } EoF The EC2 Fleet request specifies separately the target capacity for Spot and On-Demand Instances using the OnDemandTargetCapacity and SpotTargetCapacity fields inside the TargetCapacitySpecification structure. The value for DefaultTargetCapacityType specifies whether Spot or On-Demand Instances should be used to meet the TotalTargetCapacity.\nBy setting SingleInstanceType and SingleAvailabilityZone to true, you are forcing the EC2 Fleet request to provision all the instances in the same Availability Zone and of the same type.\nCopy and paste this command to create the EC2 Fleet and export its identifier to an environment variable to later monitor the status of the fleet. export FLEET_ID=$(aws ec2 create-fleet --cli-input-json file://ec2-fleet-config.json | jq -r \u0026#39;.FleetId\u0026#39;) You have now created an EC2 Fleet with request type instance!\n"
},
{
	"uri": "https://hieuminhvuu.github.io/Launching_EC2_Spot_Instance/5-creating_a_spot_interruption_experiment/",
	"title": "Creating a spot interruption experiment",
	"tags": [],
	"description": "",
	"content": "\rYou can launch Spot Instances on spare EC2 capacity for steep discounts in exchange for returning them when Amazon EC2 needs the capacity back. When Amazon EC2 reclaims a Spot Instance, we call this event a Spot Instance interruptions.\nWhen using Spot Instances, you need to be prepared for Spot Instance interruptions. One common method is to test the resiliency of your application by simulating Spot interruptions. You can trigger the Spot interruptions using AWS Fault Injection Simulator (FIS) by targeting individual Spot Instances or a subset of instances managed by services such as ASG and EC2 Fleet.\nInterrupt a Spot Instance directly from Amazon EC2 Console To trigger a Spot Instance interruption from the Amazon EC2 console, you just need to navigate to the Spot Request section. Select a Spot Instance request and then choose Actions and then Initiate interruption. Behind the scenes, we then use AWS FIS to inject the interruption in your selected Spot Instance.\nInterrupt a Spot instance in AWS FIS using AWS CLI Currently, AWS FIS has a Service Quota of maximum of 5 resources per experiment target per account per region, and Service Quota is not configurable . This means that even if your experiments targets more than 5 EC2 Spot instances, AWS FIS limits itself to 5 EC2 Spot instance being interrupted per experiment. You can get over this limit by running more than 1 experiment at a time.\nTo use AWS FIS, you run experiments on your AWS resources to test your theory of how an application or system will perform under fault conditions. To run experiments, you first create an experiment template. An experiment template is the blueprint of your experiment. It contains the actions, targets, and stop conditions for the experiment.\nIn this section, you 1- create an IAM role that grants AWS FIS the permissions to execute the experiment, 2- create a FIS experiment template, and 3- and run the experiment to trigger Spot Instance interruption.\n1. Create an IAM Role for AWS FIS To use AWS FIS, you must create an IAM role that grants AWS FIS the permissions required so that AWS FIS can run experiments on your behalf. You specify this experiment role when you create an experiment template. For more information, see Create an IAM role for AWS FIS experiments.\nThe experiment role must have a trust relationship that allows the AWS FIS service to assume the role. Create a text file named fis_role_trust_policy.json to add the trust relationship. cat \u0026lt;\u0026lt;EoF \u0026gt; ./fis_role_trust_policy.json { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowFISExperimentRoleAssumeRole\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: [ \u0026#34;fis.amazonaws.com\u0026#34; ] }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] } EoF Run create-role command to create the role with the trust policy. aws iam create-role --role-name my-fis-role --assume-role-policy-document file://fis_role_trust_policy.json The experiment requires access to perform ec2:RebootInstances, ec2:StopInstances, ec2:StartInstances, ec2:TerminateInstances , and aws:ec2:send-spot-instance-interruptions action on an EC2 Instances. Run below command to create fis_role_permissions_policy.json configuration file to add the required permission policies. cat \u0026lt;\u0026lt;EoF \u0026gt; ./fis_role_permissions_policy.json { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowFISExperimentRoleEC2Actions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:RebootInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:TerminateInstances\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:ec2:*:*:instance/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowFISExperimentRoleSpotInstanceActions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:SendSpotInstanceInterruptions\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:ec2:*:*:instance/*\u0026#34; } ] } EoF Run put-role-policy command to add these permissions to the role created earlier. aws iam put-role-policy --role-name my-fis-role --policy-name my-fis-policy --policy-document file://fis_role_permissions_policy.json Save the ARN of the role created in an environment variable to use in subsequent sections. export FIS_ROLE_ARN=$(aws iam get-role --role-name my-fis-role | jq -r \u0026#39;.Role.Arn\u0026#39;) 2. Create the Spot interruption experiment template In this step you create an experiment template that sends Spot interruption to Spot Instances launched via the EC2 Auto Scaling group or EC2 fleet in earlier chapters.\nAWS FIS experiment template contains:\nAn action, it is an activity that AWS FIS performs on an AWS resource during an experiment. In this case, you use a preconfigured action aws:ec2:send-spot-instance-interruptions, that sends a Spot Instance interruption notice to target Spot Instances two minutes before interrupting them. The action also sends an EC2 instance rebalance recommendation based on durationBeforeInterruption parameter. In this case you set preconfigured Action aws:ec2:send-spot-instance-interruptions with durationBeforeInterruption set to 2 minutes. You can change to a value greater than 2 minutes to represent a EC2 Instance rebalance recommendation coming ahead of the Spot Instance interruption notice.\nA target, it is one or more AWS resources on which AWS FIS experiment performs an action during an experiment. In this case, you set a target with aws:ec2:spot-instance as the resource type and filter the Spot Instances launched via ASG using resourceTags set to \u0026ldquo;aws:autoscaling:groupName\u0026rdquo;: \u0026ldquo;EC2SpotWorkshopASG\u0026rdquo;.\nA stop condition, it is a mechanism by AWS FIS to stop an experiment if it reaches a threshold that you define as an Amazon CloudWatch alarm. In this case, the experiment runs without a stop condition.\nCreate an experiment template using this command. cat \u0026lt;\u0026lt;EoF \u0026gt; ./spot_experiment.json { \u0026#34;description\u0026#34;: \u0026#34;Test Spot Instance interruptions\u0026#34;, \u0026#34;targets\u0026#34;: { \u0026#34;SpotInstancesInASG\u0026#34;: { \u0026#34;resourceType\u0026#34;: \u0026#34;aws:ec2:spot-instance\u0026#34;, \u0026#34;resourceTags\u0026#34;: { \u0026#34;aws:autoscaling:groupName\u0026#34;: \u0026#34;EC2SpotWorkshopASG\u0026#34; }, \u0026#34;filters\u0026#34;: [ { \u0026#34;path\u0026#34;: \u0026#34;State.Name\u0026#34;, \u0026#34;values\u0026#34;: [ \u0026#34;running\u0026#34; ] } ], \u0026#34;selectionMode\u0026#34;: \u0026#34;PERCENT(50)\u0026#34; } }, \u0026#34;actions\u0026#34;: { \u0026#34;interruptSpotInstance\u0026#34;: { \u0026#34;actionId\u0026#34;: \u0026#34;aws:ec2:send-spot-instance-interruptions\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;durationBeforeInterruption\u0026#34;: \u0026#34;PT2M\u0026#34; }, \u0026#34;targets\u0026#34;: { \u0026#34;SpotInstances\u0026#34;: \u0026#34;SpotInstancesInASG\u0026#34; } } }, \u0026#34;stopConditions\u0026#34;: [ { \u0026#34;source\u0026#34;: \u0026#34;none\u0026#34; } ], \u0026#34;roleArn\u0026#34;: \u0026#34;${FIS_ROLE_ARN}\u0026#34;, \u0026#34;tags\u0026#34;: {} } EoF Create an experiment template using the json configuration. export FIS_TEMPLATE_ID=$(aws fis create-experiment-template --cli-input-json file://spot_experiment.json | jq -r \u0026#39;.experimentTemplate.id\u0026#39;) 3. Run the Spot interruption experiment To run the experiment, you use start-experiment command to run the template created earlier. The experiment can be run multiple times to validate the results of running your application on EC2 Spot.\naws fis start-experiment --experiment-template-id $FIS_TEMPLATE_ID As the result of this experiment, you see that 50% of the Spot Instances launched by the Auto Scaling group receive the Rebalance Recommendation signals. Note that this is less than the Service Quota of 5, which is the maximum number of EC2 Spot instance that can be interrupted by a single experiment. When the actions on this experiment is complete:\nThe target Spot Instance receives an instance rebalance recommendation signal. A Spot instance interruption notice is issued two minutes before Amazon EC2 terminates your instance. After two minutes, the Spot Instance is terminated. The experiment may fail if you do not have any Spot Instances running in your EC2 Auto Scaling group or EC2 Fleet. If you encounter an error that the experiment has failed, scale up the EC2 Auto Scaling group or EC2 Fleet so that EC2 Spot instances are provisioned.\nThe Auto Scaling group setup in the example has Capacity Rebalance enabled, and hence the Auto Scaling group will start to launch EC2 Spot replacement instances when the Spot instances receive the interruption signal. You can see these events in the ASG.\nWith these tests, you can validate the resiliency of your workload to the Spot interruptions, and optionally improve the workload resiliency by implementing check-pointing or cleanup tasks.\n"
},
{
	"uri": "https://hieuminhvuu.github.io/Launching_EC2_Spot_Instance/6-savings_summary/",
	"title": "Saving summary",
	"tags": [],
	"description": "",
	"content": "Spot Savings So far we have launched Spot instances in a few ways. Here is a question: How much do you think we saved on these workloads?\nYou can check how much you have saved with Spot instances by going to the Savings Summary panel. To view your savings do the following:\nOpen the Amazon EC2 console at https://console.aws.amazon.com/ec2/. In the navigation pane, choose Spot Requests. In the top right corner of the screen, select Savings summary Spot price history \u0026amp; Spot notifications There are more APIs that you can use to learn more about Spot.\nSome projects, like the EC2 Spot Interruption Dashboard can be used as the initial point to understand which Spot Instances are being terminated and adjust your configuration by increasing diversification.\nSome other APIs might be useful to understand how the Spot price changes over time, which you can also see in the AWS Console by:\nOpen the Amazon EC2 console at https://console.aws.amazon.com/ec2/. In the navigation pane, choose Spot Requests. Choose Pricing history in the top right corner. If you are interested in how to use the Spot API programmatically, You can use the describe-spot-price-history API to retrieve the information you need.\nCost Management Tools You can also view the Spot Savings using AWS Cost Explorer, which has an easy-to-use interface that lets you visualize, understand, and manage your AWS costs and usage over time, including Spot Instances. You can use Cost Explorer filtered by “Purchase Options” to see patterns in how much you spend on Spot Instances over time, and see trends that you can use to understand your costs. You can view data up to the last 12 months, and forecast the next three months.\nAWS Customers have access to raw cost and usage data through the AWS Cost and Usage (AWS CUR) reports. These reports contain the most comprehensive information about your AWS usage and costs. If you’re using Spot Instances for your compute needs, then AWS CUR populates the Amazon EC2 Spot usage pricing columns and the product columns. With this data, you can calculate the past savings achieved with Spot through the AWS CUR.\n"
},
{
	"uri": "https://hieuminhvuu.github.io/Launching_EC2_Spot_Instance/7-spot_placement_score/",
	"title": "Spot placement score",
	"tags": [],
	"description": "",
	"content": "As Spot capacity fluctuates, you can’t be sure that you’ll always get the capacity that you need. The Spot placement score feature can recommend an AWS Region(s) or Availability Zone(s) where you can run the workload based on your Spot capacity requirements. The Spot placement score gives the Region(s) or Availability Zone(s) a score of 1 to 10 indicating how likely a Spot request will succeed. A score of 10 indicates that your Spot request is highly likely—but not guaranteed—to succeed, and a score of 1 indicates that your Spot request is not likely to succeed at all. For SPS to return a meaningful score, the SPS request must be configured with at least three instance types.\nYou can calculate a Spot placement score by using the Amazon EC2 console or the AWS CLI.\nThe same Spot placement score request can yield different scores for the same Regions or Availability Zones when calculated at different times. The same Spot placement score might be returned for different Regions or Availability Zones.\nSpot placement score can be used to\ndetermine the ability to relocate and scale Spot compute capacity in a different region if the workload is region flexible identify the most optimal Availability Zone to run the single Availability Zone workloads find an optimal configuration that will fulfill the Spot capacity needs Using Amazon EC2 console to calculate Spot placement score Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/. In the navigation pane, choose Spot Requests. Choose Spot placement score in the top right corner. Provide the inputs as show below:\nA sample output of the response on the console is show below:\nUsing AWS CLI to calculate Spot placement score You can use a json file that includes the parameters for running a Spot placement score request.\nTo get started, specify the target Spot capacity, as vCPUs or memory in MiB or in units. By specifying your target capacity in terms of the number of vCPUs or the amount of memory, you can use these units when counting the total capacity. For example, when mixing instances of different sizes, you can specify the target capacity in terms of total memory. Instances of different sizes are considered based on its memory rather than total number of instances when totaling up the target capacity.\nSpecify instance attributes or instance types. If instances can be selected based on attributes, you can use attribute-based instance type selection to specify your compute needs. If you need to use specific instances types for your workload, specify these instance types. In both cases, ensure that your request for Spot capacity includes at least a minimum of three instance types in the request.\ncat \u0026lt;\u0026lt;EoF \u0026gt; ./sps-input.json { \u0026#34;InstanceRequirementsWithMetadata\u0026#34;: { \u0026#34;ArchitectureTypes\u0026#34;: [ \u0026#34;x86_64\u0026#34; ], \u0026#34;InstanceRequirements\u0026#34;: { \u0026#34;VCpuCount\u0026#34;: { \u0026#34;Min\u0026#34;: 4, \u0026#34;Max\u0026#34;: 8 }, \u0026#34;MemoryMiB\u0026#34;: { \u0026#34;Min\u0026#34;: 16384 } } }, \u0026#34;TargetCapacity\u0026#34;: 100, \u0026#34;TargetCapacityUnitType\u0026#34;: \u0026#34;vcpu\u0026#34;, \u0026#34;SingleAvailabilityZone\u0026#34;: false } EoF In the above example, we will be running a Spot placement score for 10K vCPUs using any x86 architecture instance which has a vCPU between 4 and 8 and Memory greater than 16MB. To run the Spot placement score request with the above parameters, use this command.\naws ec2 get-spot-placement-scores --cli-input-json file://./sps-input.json Spot placement score returns the top 10 regions or top 10 Availability Zones where the specific Spot request is most likely to succeed. You can narrow down the Regions to be considered in the response. You can combine the Region filter and a request for scored Availability Zones to return a scored list of all of the Availability Zones.\n"
},
{
	"uri": "https://hieuminhvuu.github.io/Launching_EC2_Spot_Instance/8-spot_blueprints/",
	"title": "Spot Blueprint",
	"tags": [],
	"description": "",
	"content": "Spot Blueprints is a functionality provided within the AWS Web Console, in the Spot Request section, that helps to create a few architectures that are most common for Spot, using Infrastructure as code and adhering to Spot Best practices. There are Spot Blueprints for the most popular services including Amazon EC2 Auto Scaling, Amazon EMR, AWS Batch, and Amazon Elastic Kubernetes Service (Amazon EKS).\nSpot Blueprints gives you a jump start in using Spot architectures by providing a simple-to-follow infrastructure code template generator that is designed to gather your workload requirements while explaining and configuring Spot best practices along the way. The output of the process is a Cloudformation or Terraform IaaC (Infrastructure as Code) file that you can use and adapt for your projects.\nGetting started with Spot Blueprints Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/. In the navigation pane, choose Spot Requests. Choose Spot Blueprints in the top right corner.\nYou will see different categories to get you started. From there, you can either download a pre-configured blueprint in AWS CloudFormation or Terraform format, or choose to configure it. You can learn more about Spot Blueprints by reading the launch blog post. If you don’t find a blueprint that you need, feel free to provide us feedback using the Spot Blueprints Feedback link.\n"
},
{
	"uri": "https://hieuminhvuu.github.io/Launching_EC2_Spot_Instance/9-clean_up/",
	"title": "Clean up",
	"tags": [],
	"description": "",
	"content": "Before closing this workshop, let’s make sure we clean up all the resources we created so we do not incur in unexpected costs.\nDelete the AWS FIS experiment template When you are done with the FIS experiments, you can delete the experiment template.\naws fis delete-experiment-template --id $FIS_TEMPLATE_ID Delete Your Auto Scaling Group To delete your Auto Scaling group using the CLI\naws autoscaling delete-auto-scaling-group --auto-scaling-group-name EC2SpotWorkshopASG --force-delete Delete your EC2 Fleet When you are finished using your EC2 Fleet, you can delete the EC2 Fleet(s) and terminate all of the running instances.\nTo delete your EC2 Fleet and terminate the running instances using the CLI\naws ec2 delete-fleets --fleet-ids \u0026#34;${FLEET_ID}\u0026#34; --terminate-instances Terminating the Spot instances created with RunInstance You recall we created this instance with a specific Name tag. We will use the tag to search for the instance and then pass the instance-id to the terminate-instances EC2 call.\nexport INSTANCE_ID=$(aws ec2 describe-instances --filters \u0026#34;Name=tag-value,Values=EC2SpotWorkshopRunInstance\u0026#34; --query \u0026#34;Reservations[0].Instances[0].InstanceId\u0026#34; | sed s/\\\u0026#34;//g) aws ec2 terminate-instances --instance-ids $INSTANCE_ID Deleting your Spot Fleet Request Let’s now cancel or delete the Spot Fleet request. You must specify whether the Spot Fleet should terminate its Spot Instances. If you terminate the instances, the Spot Fleet request enters the cancelled_terminating state. Otherwise, the Spot Fleet request enters the cancelled_running state and the instances continue to run until they are interrupted or you terminate them manually.\nTo cancel a Spot Fleet request and terminate the running instances using the CLI\naws ec2 cancel-spot-fleet-requests --spot-fleet-request-ids \u0026#34;${SPOT_FLEET_REQUEST_ID}\u0026#34; --terminate-instances Deleting a Launch Template Finally, now that all the instances have been terminated, let’s delete the Launch Template.\naws ec2 delete-launch-template --launch-template-id \u0026#34;${LAUNCH_TEMPLATE_ID}\u0026#34; "
},
{
	"uri": "https://hieuminhvuu.github.io/Launching_EC2_Spot_Instance/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hieuminhvuu.github.io/Launching_EC2_Spot_Instance/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]